{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9868125,"sourceType":"datasetVersion","datasetId":6057270},{"sourceId":9869200,"sourceType":"datasetVersion","datasetId":6058096},{"sourceId":9869990,"sourceType":"datasetVersion","datasetId":6058702},{"sourceId":9876586,"sourceType":"datasetVersion","datasetId":6063617}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom tqdm import tqdm\nimport pandas as pd\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nimport pickle as pkl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:20:54.754211Z","iopub.execute_input":"2024-11-12T06:20:54.755199Z","iopub.status.idle":"2024-11-12T06:20:55.140178Z","shell.execute_reply.started":"2024-11-12T06:20:54.755143Z","shell.execute_reply":"2024-11-12T06:20:55.139369Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"data = []\nfor dirname, _, filenames in os.walk('/kaggle/input/hindi-dataset-3k-files'):\n    for filename in tqdm(filenames):\n        with open('/kaggle/input/hindi-dataset-3k-files/'+filename,'r') as f:\n            for x in f:\n                data.append(x)\nprint(len(data))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.DataFrame({'text':data})\ndf['text'] = df['text']+'<eos>'\ndf.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, GemmaConfig, AutoTokenizer, AutoModel, MistralConfig, MistralModel, MistralForCausalLM, LlamaConfig, LlamaForCausalLM\nimport torch\nimport torch.nn as nn\nimport torch.nn.init as init\nimport json\nimport pickle\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:20:57.097860Z","iopub.execute_input":"2024-11-12T06:20:57.098377Z","iopub.status.idle":"2024-11-12T06:21:00.079492Z","shell.execute_reply.started":"2024-11-12T06:20:57.098338Z","shell.execute_reply":"2024-11-12T06:21:00.078473Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('../input/tokenizer/')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:21:00.081579Z","iopub.execute_input":"2024-11-12T06:21:00.082664Z","iopub.status.idle":"2024-11-12T06:21:00.190156Z","shell.execute_reply.started":"2024-11-12T06:21:00.082614Z","shell.execute_reply":"2024-11-12T06:21:00.189153Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:21:00.191469Z","iopub.execute_input":"2024-11-12T06:21:00.192169Z","iopub.status.idle":"2024-11-12T06:21:00.257978Z","shell.execute_reply.started":"2024-11-12T06:21:00.192122Z","shell.execute_reply":"2024-11-12T06:21:00.256882Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"batch_size = 10000  # Adjust batch size based on available memory\ninput_ids=[]\nfor i in tqdm(range(0, len(df[\"text\"]), batch_size)):\n    batch_texts = df[\"text\"][i:i + batch_size].to_list()\n    input_ids.extend(tokenizer(batch_texts)['input_ids'])\n\nwith open('ids.pkl','wb') as f:\n    pkl.dump(input_ids,f)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open('../input/token-ids-pkl-2/ids (1).pkl','rb') as f:\n    input_ids = torch.tensor(pkl.load(f)).tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:21:04.201924Z","iopub.execute_input":"2024-11-12T06:21:04.202361Z","iopub.status.idle":"2024-11-12T06:21:12.604480Z","shell.execute_reply.started":"2024-11-12T06:21:04.202319Z","shell.execute_reply":"2024-11-12T06:21:12.603608Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  return torch.load(io.BytesIO(b))\n/tmp/ipykernel_3908/2364590555.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  input_ids = torch.tensor(pkl.load(f)).tolist()\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:21:12.606194Z","iopub.execute_input":"2024-11-12T06:21:12.606521Z","iopub.status.idle":"2024-11-12T06:21:13.352721Z","shell.execute_reply.started":"2024-11-12T06:21:12.606489Z","shell.execute_reply":"2024-11-12T06:21:13.351763Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"token_list = []\nfor i in tqdm(input_ids[:len(input_ids)]):\n    token_list.extend(i)\n\ngc.collect()\nlen(token_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:56:58.084558Z","iopub.execute_input":"2024-11-12T06:56:58.085305Z","iopub.status.idle":"2024-11-12T06:57:02.139648Z","shell.execute_reply.started":"2024-11-12T06:56:58.085261Z","shell.execute_reply":"2024-11-12T06:57:02.138668Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 4797315/4797315 [00:02<00:00, 1803868.36it/s]\n","output_type":"stream"},{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"47973150"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"df = pd.DataFrame(columns=[\"input_ids\"])\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:57:02.141667Z","iopub.execute_input":"2024-11-12T06:57:02.142092Z","iopub.status.idle":"2024-11-12T06:57:02.152964Z","shell.execute_reply.started":"2024-11-12T06:57:02.142046Z","shell.execute_reply":"2024-11-12T06:57:02.152086Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"Empty DataFrame\nColumns: [input_ids]\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input_ids</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"context_len = 64      ## Taking less because I have less data\ntoken_batch = []\nfor i in tqdm(range(0,len(token_list),context_len)):\n  token_batch.append(token_list[i:i+context_len])\n  # token_list = token_list[context_len:]\nlen(token_batch[-1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:57:02.154141Z","iopub.execute_input":"2024-11-12T06:57:02.154437Z","iopub.status.idle":"2024-11-12T06:57:03.740675Z","shell.execute_reply.started":"2024-11-12T06:57:02.154404Z","shell.execute_reply":"2024-11-12T06:57:03.739712Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 749581/749581 [00:01<00:00, 477775.57it/s]\n","output_type":"stream"},{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"30"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"print(len(token_batch))\nprint(len(token_batch[0]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:57:03.742812Z","iopub.execute_input":"2024-11-12T06:57:03.743143Z","iopub.status.idle":"2024-11-12T06:57:03.748303Z","shell.execute_reply.started":"2024-11-12T06:57:03.743110Z","shell.execute_reply":"2024-11-12T06:57:03.747243Z"}},"outputs":[{"name":"stdout","text":"749581\n64\n","output_type":"stream"}],"execution_count":44},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"df[\"input_ids\"] = token_batch\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:57:03.749757Z","iopub.execute_input":"2024-11-12T06:57:03.750410Z","iopub.status.idle":"2024-11-12T06:57:04.055739Z","shell.execute_reply.started":"2024-11-12T06:57:03.750363Z","shell.execute_reply":"2024-11-12T06:57:04.054836Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"                                                input_ids\n0       [1673, 3195, 1599, 4276, 1323, 1624, 1945, 110...\n1       [1323, 1624, 1945, 1104, 1627, 3139, 1847, 444...\n2       [1581, 1034, 13388, 2393, 1410, 2341, 4613, 31...\n3       [1410, 2341, 4613, 3195, 20340, 1, 84, 2997, 1...\n4       [1448, 3481, 1307, 3271, 1401, 1751, 1026, 191...\n...                                                   ...\n749576  [1082, 2823, 2102, 1082, 2865, 1666, 0, 0, 0, ...\n749577  [2997, 46, 3526, 2227, 4166, 1105, 1146, 3413,...\n749578  [0, 0, 2717, 5776, 1, 84, 2997, 46, 2369, 8599...\n749579  [1053, 2211, 1830, 16829, 0, 3477, 1111, 1710,...\n749580  [1560, 2081, 1053, 1441, 1635, 5436, 16766, 37...\n\n[749581 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input_ids</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[1673, 3195, 1599, 4276, 1323, 1624, 1945, 110...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[1323, 1624, 1945, 1104, 1627, 3139, 1847, 444...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[1581, 1034, 13388, 2393, 1410, 2341, 4613, 31...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[1410, 2341, 4613, 3195, 20340, 1, 84, 2997, 1...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[1448, 3481, 1307, 3271, 1401, 1751, 1026, 191...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>749576</th>\n      <td>[1082, 2823, 2102, 1082, 2865, 1666, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>749577</th>\n      <td>[2997, 46, 3526, 2227, 4166, 1105, 1146, 3413,...</td>\n    </tr>\n    <tr>\n      <th>749578</th>\n      <td>[0, 0, 2717, 5776, 1, 84, 2997, 46, 2369, 8599...</td>\n    </tr>\n    <tr>\n      <th>749579</th>\n      <td>[1053, 2211, 1830, 16829, 0, 3477, 1111, 1710,...</td>\n    </tr>\n    <tr>\n      <th>749580</th>\n      <td>[1560, 2081, 1053, 1441, 1635, 5436, 16766, 37...</td>\n    </tr>\n  </tbody>\n</table>\n<p>749581 rows × 1 columns</p>\n</div>"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"attn_mask = [[1]*64]*len(df)\ndf[\"attention_mask\"] = attn_mask\ndf['labels'] = df['input_ids']\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:57:04.057133Z","iopub.execute_input":"2024-11-12T06:57:04.057455Z","iopub.status.idle":"2024-11-12T06:57:04.206649Z","shell.execute_reply.started":"2024-11-12T06:57:04.057421Z","shell.execute_reply":"2024-11-12T06:57:04.205697Z"}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"                                           input_ids  \\\n0  [1673, 3195, 1599, 4276, 1323, 1624, 1945, 110...   \n1  [1323, 1624, 1945, 1104, 1627, 3139, 1847, 444...   \n2  [1581, 1034, 13388, 2393, 1410, 2341, 4613, 31...   \n3  [1410, 2341, 4613, 3195, 20340, 1, 84, 2997, 1...   \n4  [1448, 3481, 1307, 3271, 1401, 1751, 1026, 191...   \n\n                                      attention_mask  \\\n0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n\n                                              labels  \n0  [1673, 3195, 1599, 4276, 1323, 1624, 1945, 110...  \n1  [1323, 1624, 1945, 1104, 1627, 3139, 1847, 444...  \n2  [1581, 1034, 13388, 2393, 1410, 2341, 4613, 31...  \n3  [1410, 2341, 4613, 3195, 20340, 1, 84, 2997, 1...  \n4  [1448, 3481, 1307, 3271, 1401, 1751, 1026, 191...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[1673, 3195, 1599, 4276, 1323, 1624, 1945, 110...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n      <td>[1673, 3195, 1599, 4276, 1323, 1624, 1945, 110...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[1323, 1624, 1945, 1104, 1627, 3139, 1847, 444...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n      <td>[1323, 1624, 1945, 1104, 1627, 3139, 1847, 444...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[1581, 1034, 13388, 2393, 1410, 2341, 4613, 31...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n      <td>[1581, 1034, 13388, 2393, 1410, 2341, 4613, 31...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[1410, 2341, 4613, 3195, 20340, 1, 84, 2997, 1...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n      <td>[1410, 2341, 4613, 3195, 20340, 1, 84, 2997, 1...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[1448, 3481, 1307, 3271, 1401, 1751, 1026, 191...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n      <td>[1448, 3481, 1307, 3271, 1401, 1751, 1026, 191...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"# !pip install datasets\nfrom datasets import Dataset, DatasetDict\nfrom datasets import load_dataset\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:57:04.207730Z","iopub.execute_input":"2024-11-12T06:57:04.208075Z","iopub.status.idle":"2024-11-12T06:57:04.213149Z","shell.execute_reply.started":"2024-11-12T06:57:04.208039Z","shell.execute_reply":"2024-11-12T06:57:04.212197Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"# import torch_xla\n# import torch_xla.core.xla_model as xm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:57:04.214457Z","iopub.execute_input":"2024-11-12T06:57:04.214837Z","iopub.status.idle":"2024-11-12T06:57:04.220432Z","shell.execute_reply.started":"2024-11-12T06:57:04.214791Z","shell.execute_reply":"2024-11-12T06:57:04.219485Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"# hf_dataset = Dataset.from_pandas(df[:1000])\n# split_dataset = hf_dataset.train_test_split(test_size=0.1)  # Adjust test_size as needed\n\n# train_dataset = split_dataset['train']\n# eval_dataset = split_dataset['test']\n\n# Assuming df is your original DataFrame\nmax_len = len(df)\ndf2 = df[:max_len]\ntrain_size = int(0.9 * len(df2))  # Calculate 90% of the dataset length\n\n# Split the DataFrame\ntrain_df = df2[:train_size]  # First 90% for training\neval_df = df2[train_size:]   # Remaining 10% for evaluation\nprint('split done')\n# Convert each split to Hugging Face Dataset\ntrain_dataset = Dataset.from_pandas(train_df)\nprint('train converted')\neval_dataset = Dataset.from_pandas(eval_df)\nprint('test converted')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:57:04.221493Z","iopub.execute_input":"2024-11-12T06:57:04.221819Z","iopub.status.idle":"2024-11-12T06:57:24.653864Z","shell.execute_reply.started":"2024-11-12T06:57:04.221780Z","shell.execute_reply":"2024-11-12T06:57:24.652936Z"}},"outputs":[{"name":"stdout","text":"split done\ntrain converted\ntest converted\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"train_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:57:24.657382Z","iopub.execute_input":"2024-11-12T06:57:24.657707Z","iopub.status.idle":"2024-11-12T06:57:24.663808Z","shell.execute_reply.started":"2024-11-12T06:57:24.657673Z","shell.execute_reply":"2024-11-12T06:57:24.662829Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids', 'attention_mask', 'labels'],\n    num_rows: 674622\n})"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset.to_parquet(\"hi_dataset_token_train.parquet\")\neval_dataset.to_parquet(\"hi_dataset_token_test.parquet\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:57:24.664934Z","iopub.execute_input":"2024-11-12T06:57:24.665266Z","iopub.status.idle":"2024-11-12T06:57:28.557389Z","shell.execute_reply.started":"2024-11-12T06:57:24.665233Z","shell.execute_reply":"2024-11-12T06:57:28.556388Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/675 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed81d3ce64ba4cd186feb9bbaae1f662"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/75 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d58d44e1cda40f5b4c54425c3b2d723"}},"metadata":{}},{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"116035988"},"metadata":{}}],"execution_count":51},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:57:28.558801Z","iopub.execute_input":"2024-11-12T06:57:28.559235Z","iopub.status.idle":"2024-11-12T06:57:28.563986Z","shell.execute_reply.started":"2024-11-12T06:57:28.559188Z","shell.execute_reply":"2024-11-12T06:57:28.563057Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# config = LlamaConfig(hidden_size=256,\n#                      vocab_size=len(tokenizer.vocab),\n#                      num_attention_heads=4,\n#                      num_key_value_heads=2,\n#                      num_hidden_layers=12,\n#                      intermediate_size=688,\n#                      max_position_embeddings=64)\n\nconfig = LlamaConfig(hidden_size=768,\n                     vocab_size=32000,\n                     num_attention_heads=8,\n                     num_key_value_heads=2,\n                     num_hidden_layers=8,\n                     intermediate_size=1024,\n                     max_position_embeddings=64)\n\nprint(config)\nmodel_mis = LlamaForCausalLM(config)\n\n# Move model to TPU\nmodel_mis.to(device)\n\nfor i,j in model_mis.named_parameters():\n  if j.requires_grad and len(j.size()) > 1:\n    init.xavier_uniform_(j.data)\n\ntotal_param=0\nfor i,j in model_mis.named_parameters():\n    total_param += j.numel()\nprint(total_param/(10**6))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:57:28.565157Z","iopub.execute_input":"2024-11-12T06:57:28.565466Z","iopub.status.idle":"2024-11-12T06:57:29.938941Z","shell.execute_reply.started":"2024-11-12T06:57:28.565416Z","shell.execute_reply":"2024-11-12T06:57:29.937955Z"}},"outputs":[{"name":"stdout","text":"LlamaConfig {\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"head_dim\": 96,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 1024,\n  \"max_position_embeddings\": 64,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 8,\n  \"num_hidden_layers\": 8,\n  \"num_key_value_heads\": 2,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 10000.0,\n  \"tie_word_embeddings\": false,\n  \"transformers_version\": \"4.45.1\",\n  \"use_cache\": true,\n  \"vocab_size\": 32000\n}\n\n79.835904\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./hi_model\",\n    overwrite_output_dir=True,\n    num_train_epochs=10,\n    logging_steps=500,\n    learning_rate=2e-3,\n    fp16=True,\n    do_train=True,\n    per_device_train_batch_size=64,\n    save_steps=20000,\n    save_total_limit=2,\n    report_to=\"none\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:58:23.506792Z","iopub.execute_input":"2024-11-12T06:58:23.507197Z","iopub.status.idle":"2024-11-12T06:58:23.542361Z","shell.execute_reply.started":"2024-11-12T06:58:23.507164Z","shell.execute_reply":"2024-11-12T06:58:23.541528Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"trainer = Trainer(\n    model=model_mis,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    tokenizer=tokenizer,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:58:23.785353Z","iopub.execute_input":"2024-11-12T06:58:23.786120Z","iopub.status.idle":"2024-11-12T06:58:23.800411Z","shell.execute_reply.started":"2024-11-12T06:58:23.786079Z","shell.execute_reply":"2024-11-12T06:58:23.799340Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"tokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:58:24.984936Z","iopub.execute_input":"2024-11-12T06:58:24.985782Z","iopub.status.idle":"2024-11-12T06:58:24.990048Z","shell.execute_reply.started":"2024-11-12T06:58:24.985740Z","shell.execute_reply":"2024-11-12T06:58:24.989036Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"torch.cuda.reset_max_memory_allocated()\ntorch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:58:25.636118Z","iopub.execute_input":"2024-11-12T06:58:25.637057Z","iopub.status.idle":"2024-11-12T06:58:25.829214Z","shell.execute_reply.started":"2024-11-12T06:58:25.637016Z","shell.execute_reply":"2024-11-12T06:58:25.828142Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/cuda/memory.py:343: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"# torch.cuda.empty_cache()\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:58:37.386937Z","iopub.execute_input":"2024-11-12T06:58:37.387338Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12688' max='52710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12688/52710 2:06:49 < 6:40:05, 1.67 it/s, Epoch 2.41/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>5.591900</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>4.476500</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>3.984600</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>3.699100</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>3.498500</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>3.332400</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>3.192900</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>3.060700</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>2.952100</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>2.854800</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>2.745500</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>2.619300</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>2.544100</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>2.496000</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>2.419300</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>2.353800</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>2.313000</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>2.229000</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>2.167200</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>2.105400</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>2.065300</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>1.952300</td>\n    </tr>\n    <tr>\n      <td>11500</td>\n      <td>1.918700</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>1.893400</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>1.852000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"custom_input = \"जब मैंने उसे देखा तो वह मंदिर जा रहा था\"\ninput_dict = {'text': [custom_input]}\ninput_dict = {'input_ids': [tokenizer.encode(custom_input)]}\ninput_dict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:51:05.003720Z","iopub.execute_input":"2024-11-12T06:51:05.004923Z","iopub.status.idle":"2024-11-12T06:51:05.012024Z","shell.execute_reply.started":"2024-11-12T06:51:05.004855Z","shell.execute_reply":"2024-11-12T06:51:05.010969Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [[1407, 2150, 1815, 2540, 1131, 1409, 2676, 1101, 1296, 1200]]}"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"custom_dataset = Dataset.from_dict(input_dict)\npredictions = trainer.predict(custom_dataset)\ngenerated_outputs = predictions.predictions  # This will be logits\noutput_ids = torch.argmax(torch.tensor(generated_outputs), dim=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:51:06.085938Z","iopub.execute_input":"2024-11-12T06:51:06.086379Z","iopub.status.idle":"2024-11-12T06:51:06.127093Z","shell.execute_reply.started":"2024-11-12T06:51:06.086327Z","shell.execute_reply":"2024-11-12T06:51:06.126083Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"tokenizer.decode(output_ids[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:51:06.604981Z","iopub.execute_input":"2024-11-12T06:51:06.605379Z","iopub.status.idle":"2024-11-12T06:51:06.611880Z","shell.execute_reply.started":"2024-11-12T06:51:06.605344Z","shell.execute_reply":"2024-11-12T06:51:06.610972Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"'भी उस टी - नहीं तो में कर था बड़े'"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"output_ids","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:49:55.187994Z","iopub.execute_input":"2024-11-12T06:49:55.188375Z","iopub.status.idle":"2024-11-12T06:49:55.199352Z","shell.execute_reply.started":"2024-11-12T06:49:55.188341Z","shell.execute_reply":"2024-11-12T06:49:55.198333Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"tensor([[12229,  9929,  1086,     0, 15643,  5714, 12988,  3907,     0,    63,\n          4086,  1449,  1259,  8866]])"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"import math\nmodel = AutoModelForCausalLM.from_pretrained('trained_model')\ndef calculate_perplexity(text):\n    inputs = tokenizer(text, return_tensors=\"pt\")\n    input_ids = inputs[\"input_ids\"]\n\n    with torch.no_grad():\n        outputs = model(input_ids, labels=input_ids)\n        loss = outputs.loss\n        perplexity = math.exp(loss.item())\n\n    return perplexity\n\ntext = \"जब मैंने उसे देखा तो वह मंदिर जा रहा था\"\nperplexity = calculate_perplexity(text)\nprint(f\"Perplexity: {perplexity}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:55:27.284911Z","iopub.execute_input":"2024-11-12T06:55:27.285311Z","iopub.status.idle":"2024-11-12T06:55:27.389745Z","shell.execute_reply.started":"2024-11-12T06:55:27.285271Z","shell.execute_reply":"2024-11-12T06:55:27.388741Z"}},"outputs":[{"name":"stdout","text":"Perplexity: 27386.954747318174\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"trainer.save_model(\"trained_model\")\ntokenizer.save_pretrained(\"trained_model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:49:56.681197Z","iopub.execute_input":"2024-11-12T06:49:56.681924Z","iopub.status.idle":"2024-11-12T06:49:57.472390Z","shell.execute_reply.started":"2024-11-12T06:49:56.681867Z","shell.execute_reply":"2024-11-12T06:49:57.471416Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"('trained_model/tokenizer_config.json',\n 'trained_model/special_tokens_map.json',\n 'trained_model/tokenizer.json')"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}