{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9907935,"sourceType":"datasetVersion","datasetId":6087353}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom tqdm import tqdm\nimport pandas as pd\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nimport pickle as pkl\nimport math\nfrom transformers import AutoModelForCausalLM, GemmaConfig, AutoTokenizer, AutoModel, MistralConfig, MistralModel, MistralForCausalLM, LlamaConfig, LlamaForCausalLM\nimport torch\nimport torch.nn as nn\nimport torch.nn.init as init\nimport json\nimport pickle\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-14T17:22:21.564699Z","iopub.execute_input":"2024-11-14T17:22:21.565089Z","iopub.status.idle":"2024-11-14T17:22:27.859729Z","shell.execute_reply.started":"2024-11-14T17:22:21.565044Z","shell.execute_reply":"2024-11-14T17:22:27.858778Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# 10 sentence prediction\n\nmodel_name_or_path = \"/kaggle/input/ps-v2-output/hi_model/checkpoint-52710\"  # Update with your model path\ntokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\nmodel = AutoModelForCausalLM.from_pretrained(model_name_or_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T17:22:27.861535Z","iopub.execute_input":"2024-11-14T17:22:27.862157Z","iopub.status.idle":"2024-11-14T17:22:28.521670Z","shell.execute_reply.started":"2024-11-14T17:22:27.862123Z","shell.execute_reply":"2024-11-14T17:22:28.520883Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def calculate_perplexity_and_generate(model, tokenizer, sentences, max_length=50):\n    model.eval()\n    perplexities = []\n    generated_texts = []\n\n    with torch.no_grad():\n        for sentence in sentences:\n            # Tokenize the sentence\n            inputs = tokenizer(sentence, return_tensors=\"pt\")\n            input_ids = inputs.input_ids\n\n            # Forward pass to calculate perplexity\n            outputs = model(input_ids, labels=input_ids)\n            loss = outputs.loss\n            perplexity = math.exp(loss.item())\n            perplexities.append(perplexity)\n\n            # Generate text based on the input\n            generated_ids = model.generate(\n                input_ids, max_length=max_length, do_sample=True\n            )\n            decoded_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n            generated_texts.append(decoded_text)\n\n    return perplexities, generated_texts\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T17:22:28.523127Z","iopub.execute_input":"2024-11-14T17:22:28.523779Z","iopub.status.idle":"2024-11-14T17:22:28.531015Z","shell.execute_reply.started":"2024-11-14T17:22:28.523734Z","shell.execute_reply":"2024-11-14T17:22:28.530138Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"hindi_sentences = [\n    \"यह एक उदाहरण वाक्य है।\",\n    \"मुझे किताबें पढ़ना पसंद है।\",\n    \"भारत एक सुंदर देश है।\",\n    \"आज मौसम बहुत अच्छा है।\",\n    \"वह स्कूल जा रहा है।\",\n    \"मैं संगीत सुन रहा हूँ।\",\n    \"यह बहुत कठिन प्रश्न है।\",\n    \"हमें अपना काम समय पर करना चाहिए।\",\n    \"कृपया अपनी सहायता प्रदान करें।\",\n    \"हम कल यात्रा पर जाएंगे।\"\n]\n\nperplexities, generated_texts = calculate_perplexity_and_generate(model, tokenizer, hindi_sentences)\nfor i, sentence in enumerate(hindi_sentences):\n    print(f\"Sentence: {sentence}\")\n    print(f\"Perplexity: {perplexities[i]}\")\n    print(f\"Generated Text: {generated_texts[i]}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T17:22:28.532772Z","iopub.execute_input":"2024-11-14T17:22:28.533083Z","iopub.status.idle":"2024-11-14T17:22:39.303276Z","shell.execute_reply.started":"2024-11-14T17:22:28.533050Z","shell.execute_reply":"2024-11-14T17:22:39.302301Z"}},"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nStarting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sentence: यह एक उदाहरण वाक्य है।\nPerplexity: 57860.420222356624\nGenerated Text: यह एक उदाहरण वाक्य है कि हम अमर्त्य सेन: विवादों में यह कार्य जैसे बैंक के भावनात्मक इसके लिए लठरीय सूचनािंग और किसी भी प्रकाशित की जा रही है\neos यह वह चसेनजित व कोसिओगी यह आधुनिक काव्य\n\nSentence: मुझे किताबें पढ़ना पसंद है।\nPerplexity: 63896459.160597876\nGenerated Text: मुझे किताबें पढ़ना पसंद है ... एक सपना अपने लिए और सबके शनिवार\neos> इसे \"समझले ही इस तरह के भी आर्टिकल दश नियंत्रण के लिए यहाँ क्लिक कर काफी पहले लगता है कि किस मिट्टी में यह गर्वी फूलों के पीछे\n\nSentence: भारत एक सुंदर देश है।\nPerplexity: 162681.85668559006\nGenerated Text: भारत एक सुंदर देश है इस शहर में जहाँ फिर भी यही बात उसके लिये आग है ही...  दिसंबर  में हम इंसान  दिसंबर दिसंबर 2019 शुक्रवार\neos> 2015 मुझे क्यों मारना शायद मालूम नहीं\n\nSentence: आज मौसम बहुत अच्छा है।\nPerplexity: 23641.880885594837\nGenerated Text: आज मौसम बहुत अच्छा है उस पर चलना चाहता मित्र मे इस बात पर मुझे याद पड़ता पर अपना साथ और फिर जब हमारा सामान देखने पर सोचने–जाने लगता है. कुछ देर तक बता वो जानती थी कि यह सब लेकिन क्या कोई सुधार रखो कोई\n\nSentence: वह स्कूल जा रहा है।\nPerplexity: 22574.75738643322\nGenerated Text: वह स्कूल जा रहा है नागरिक एक परिवार के लिए प्रेस की खैश से व्याख्या- यह अभी संभव है कि उसके ब्लाग इस युग में भी अनेक लोग ऐसे हैं जिनके लिए इस विखंड\neos> तथा 10 लाख\n\nSentence: मैं संगीत सुन रहा हूँ।\nPerplexity: 23538676.29424916\nGenerated Text: मैं संगीत सुन रहा हूँ की अपनी रौशनी बदल और मुझे मेरी कोशिश में आया और उन्होने मेरे पति (मेरे पापा नीम का गुढल(कंग) बूढ़ा थे\neos> ( फणीश्वर की कहानी नहीं है राखी में चार तुम वहीं\n\nSentence: यह बहुत कठिन प्रश्न है।\nPerplexity: 34675.60241969935\nGenerated Text: यह बहुत कठिन प्रश्न है और इसका कहें दीपक बापू पुल की बाड़ी को हमने भिन्न-भिन्न पत्रिकाओं में अखबार \neos> गन्दगी \neos> mahadev desai \neos>\n\nSentence: हमें अपना काम समय पर करना चाहिए।\nPerplexity: 73165.72616203703\nGenerated Text: हमें अपना काम समय पर करना चाहिए आदमी इस रूप में अक्षरों को सोचता है कि हिंदी के पूर्वी भाग को तथापि देवनागरी लिपि में समाज को दबाते हैं\neos इस चिराग की कहानी को समझ में बस्त तब सबकुछ जानने में संकोच\n\nSentence: कृपया अपनी सहायता प्रदान करें।\nPerplexity: 174687.35242452077\nGenerated Text: कृपया अपनी सहायता प्रदान करें कि मनोविज्ञान कथन किसी हम घर में सही मानकर पर हो तथा छ इस तरह तो वह ऐसा इंसान की ही तरह जानते हैं\n  अब कोई नज़्म में था\neos\n\nSentence: हम कल यात्रा पर जाएंगे।\nPerplexity: 616945714.7728281\nGenerated Text: हम कल यात्रा पर जाएंगे मजबूर खून दो\n मेरी आंखें में जब यूँ भी मूल बदलाव हुए हैं तब मधुर जब हम खुद को अलग रूप से लगा \n और फ़िर वापिस आने वाली बात को डर से बाहर क्या खुद ही जानती हूँ\neos\n\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}