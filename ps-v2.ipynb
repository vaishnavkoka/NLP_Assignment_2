{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9869200,"sourceType":"datasetVersion","datasetId":6058096},{"sourceId":9869990,"sourceType":"datasetVersion","datasetId":6058702},{"sourceId":9876586,"sourceType":"datasetVersion","datasetId":6063617}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom tqdm import tqdm\nimport pandas as pd\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nimport pickle as pkl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:20:54.754211Z","iopub.execute_input":"2024-11-12T06:20:54.755199Z","iopub.status.idle":"2024-11-12T06:20:55.140178Z","shell.execute_reply.started":"2024-11-12T06:20:54.755143Z","shell.execute_reply":"2024-11-12T06:20:55.139369Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, GemmaConfig, AutoTokenizer, AutoModel, MistralConfig, MistralModel, MistralForCausalLM, LlamaConfig, LlamaForCausalLM\nimport torch\nimport torch.nn as nn\nimport torch.nn.init as init\nimport json\nimport pickle\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:20:57.097860Z","iopub.execute_input":"2024-11-12T06:20:57.098377Z","iopub.status.idle":"2024-11-12T06:21:00.079492Z","shell.execute_reply.started":"2024-11-12T06:20:57.098338Z","shell.execute_reply":"2024-11-12T06:21:00.078473Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('../input/tokenizer/')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:21:00.081579Z","iopub.execute_input":"2024-11-12T06:21:00.082664Z","iopub.status.idle":"2024-11-12T06:21:00.190156Z","shell.execute_reply.started":"2024-11-12T06:21:00.082614Z","shell.execute_reply":"2024-11-12T06:21:00.189153Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:21:00.191469Z","iopub.execute_input":"2024-11-12T06:21:00.192169Z","iopub.status.idle":"2024-11-12T06:21:00.257978Z","shell.execute_reply.started":"2024-11-12T06:21:00.192122Z","shell.execute_reply":"2024-11-12T06:21:00.256882Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open('../input/token-ids-pkl-2/ids (1).pkl','rb') as f:\n    input_ids = torch.tensor(pkl.load(f)).tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:21:04.201924Z","iopub.execute_input":"2024-11-12T06:21:04.202361Z","iopub.status.idle":"2024-11-12T06:21:12.604480Z","shell.execute_reply.started":"2024-11-12T06:21:04.202319Z","shell.execute_reply":"2024-11-12T06:21:12.603608Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:21:12.606194Z","iopub.execute_input":"2024-11-12T06:21:12.606521Z","iopub.status.idle":"2024-11-12T06:21:13.352721Z","shell.execute_reply.started":"2024-11-12T06:21:12.606489Z","shell.execute_reply":"2024-11-12T06:21:13.351763Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"token_list = []\nfor i in tqdm(input_ids[:len(input_ids)]):\n    token_list.extend(i)\n\ngc.collect()\nlen(token_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:56:58.084558Z","iopub.execute_input":"2024-11-12T06:56:58.085305Z","iopub.status.idle":"2024-11-12T06:57:02.139648Z","shell.execute_reply.started":"2024-11-12T06:56:58.085261Z","shell.execute_reply":"2024-11-12T06:57:02.138668Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.DataFrame(columns=[\"input_ids\"])\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:57:02.141667Z","iopub.execute_input":"2024-11-12T06:57:02.142092Z","iopub.status.idle":"2024-11-12T06:57:02.152964Z","shell.execute_reply.started":"2024-11-12T06:57:02.142046Z","shell.execute_reply":"2024-11-12T06:57:02.152086Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"context_len = 64      ## Taking less because I have less data\ntoken_batch = []\nfor i in tqdm(range(0,len(token_list),context_len)):\n  token_batch.append(token_list[i:i+context_len])\n  # token_list = token_list[context_len:]\nlen(token_batch[-1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:57:02.154141Z","iopub.execute_input":"2024-11-12T06:57:02.154437Z","iopub.status.idle":"2024-11-12T06:57:03.740675Z","shell.execute_reply.started":"2024-11-12T06:57:02.154404Z","shell.execute_reply":"2024-11-12T06:57:03.739712Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(token_batch))\nprint(len(token_batch[0]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:57:03.742812Z","iopub.execute_input":"2024-11-12T06:57:03.743143Z","iopub.status.idle":"2024-11-12T06:57:03.748303Z","shell.execute_reply.started":"2024-11-12T06:57:03.743110Z","shell.execute_reply":"2024-11-12T06:57:03.747243Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"df[\"input_ids\"] = token_batch\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:57:03.749757Z","iopub.execute_input":"2024-11-12T06:57:03.750410Z","iopub.status.idle":"2024-11-12T06:57:04.055739Z","shell.execute_reply.started":"2024-11-12T06:57:03.750363Z","shell.execute_reply":"2024-11-12T06:57:04.054836Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"attn_mask = [[1]*64]*len(df)\ndf[\"attention_mask\"] = attn_mask\ndf['labels'] = df['input_ids']\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:57:04.057133Z","iopub.execute_input":"2024-11-12T06:57:04.057455Z","iopub.status.idle":"2024-11-12T06:57:04.206649Z","shell.execute_reply.started":"2024-11-12T06:57:04.057421Z","shell.execute_reply":"2024-11-12T06:57:04.205697Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !pip install datasets\nfrom datasets import Dataset, DatasetDict\nfrom datasets import load_dataset\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:57:04.207730Z","iopub.execute_input":"2024-11-12T06:57:04.208075Z","iopub.status.idle":"2024-11-12T06:57:04.213149Z","shell.execute_reply.started":"2024-11-12T06:57:04.208039Z","shell.execute_reply":"2024-11-12T06:57:04.212197Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import torch_xla\n# import torch_xla.core.xla_model as xm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:57:04.214457Z","iopub.execute_input":"2024-11-12T06:57:04.214837Z","iopub.status.idle":"2024-11-12T06:57:04.220432Z","shell.execute_reply.started":"2024-11-12T06:57:04.214791Z","shell.execute_reply":"2024-11-12T06:57:04.219485Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# hf_dataset = Dataset.from_pandas(df[:1000])\n# split_dataset = hf_dataset.train_test_split(test_size=0.1)  # Adjust test_size as needed\n\n# train_dataset = split_dataset['train']\n# eval_dataset = split_dataset['test']\n\n# Assuming df is your original DataFrame\nmax_len = len(df)\ndf2 = df[:max_len]\ntrain_size = int(0.9 * len(df2))  # Calculate 90% of the dataset length\n\n# Split the DataFrame\ntrain_df = df2[:train_size]  # First 90% for training\neval_df = df2[train_size:]   # Remaining 10% for evaluation\nprint('split done')\n# Convert each split to Hugging Face Dataset\ntrain_dataset = Dataset.from_pandas(train_df)\nprint('train converted')\neval_dataset = Dataset.from_pandas(eval_df)\nprint('test converted')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:57:04.221493Z","iopub.execute_input":"2024-11-12T06:57:04.221819Z","iopub.status.idle":"2024-11-12T06:57:24.653864Z","shell.execute_reply.started":"2024-11-12T06:57:04.221780Z","shell.execute_reply":"2024-11-12T06:57:24.652936Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:57:24.657382Z","iopub.execute_input":"2024-11-12T06:57:24.657707Z","iopub.status.idle":"2024-11-12T06:57:24.663808Z","shell.execute_reply.started":"2024-11-12T06:57:24.657673Z","shell.execute_reply":"2024-11-12T06:57:24.662829Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset.to_parquet(\"hi_dataset_token_train.parquet\")\neval_dataset.to_parquet(\"hi_dataset_token_test.parquet\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:57:24.664934Z","iopub.execute_input":"2024-11-12T06:57:24.665266Z","iopub.status.idle":"2024-11-12T06:57:28.557389Z","shell.execute_reply.started":"2024-11-12T06:57:24.665233Z","shell.execute_reply":"2024-11-12T06:57:28.556388Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:57:28.558801Z","iopub.execute_input":"2024-11-12T06:57:28.559235Z","iopub.status.idle":"2024-11-12T06:57:28.563986Z","shell.execute_reply.started":"2024-11-12T06:57:28.559188Z","shell.execute_reply":"2024-11-12T06:57:28.563057Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# config = LlamaConfig(hidden_size=256,\n#                      vocab_size=len(tokenizer.vocab),\n#                      num_attention_heads=4,\n#                      num_key_value_heads=2,\n#                      num_hidden_layers=12,\n#                      intermediate_size=688,\n#                      max_position_embeddings=64)\n\nconfig = LlamaConfig(hidden_size=768,\n                     vocab_size=32000,\n                     num_attention_heads=8,\n                     num_key_value_heads=2,\n                     num_hidden_layers=8,\n                     intermediate_size=1024,\n                     max_position_embeddings=64)\n\nprint(config)\nmodel_mis = LlamaForCausalLM(config)\n\n# Move model to TPU\nmodel_mis.to(device)\n\nfor i,j in model_mis.named_parameters():\n  if j.requires_grad and len(j.size()) > 1:\n    init.xavier_uniform_(j.data)\n\ntotal_param=0\nfor i,j in model_mis.named_parameters():\n    total_param += j.numel()\nprint(total_param/(10**6))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:57:28.565157Z","iopub.execute_input":"2024-11-12T06:57:28.565466Z","iopub.status.idle":"2024-11-12T06:57:29.938941Z","shell.execute_reply.started":"2024-11-12T06:57:28.565416Z","shell.execute_reply":"2024-11-12T06:57:29.937955Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./hi_model\",\n    overwrite_output_dir=True,\n    num_train_epochs=10,\n    logging_steps=500,\n    learning_rate=2e-3,\n    fp16=True,\n    do_train=True,\n    per_device_train_batch_size=64,\n    save_steps=20000,\n    save_total_limit=2,\n    report_to=\"none\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:58:23.506792Z","iopub.execute_input":"2024-11-12T06:58:23.507197Z","iopub.status.idle":"2024-11-12T06:58:23.542361Z","shell.execute_reply.started":"2024-11-12T06:58:23.507164Z","shell.execute_reply":"2024-11-12T06:58:23.541528Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = Trainer(\n    model=model_mis,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    tokenizer=tokenizer,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:58:23.785353Z","iopub.execute_input":"2024-11-12T06:58:23.786120Z","iopub.status.idle":"2024-11-12T06:58:23.800411Z","shell.execute_reply.started":"2024-11-12T06:58:23.786079Z","shell.execute_reply":"2024-11-12T06:58:23.799340Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:58:24.984936Z","iopub.execute_input":"2024-11-12T06:58:24.985782Z","iopub.status.idle":"2024-11-12T06:58:24.990048Z","shell.execute_reply.started":"2024-11-12T06:58:24.985740Z","shell.execute_reply":"2024-11-12T06:58:24.989036Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.cuda.reset_max_memory_allocated()\ntorch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:58:25.636118Z","iopub.execute_input":"2024-11-12T06:58:25.637057Z","iopub.status.idle":"2024-11-12T06:58:25.829214Z","shell.execute_reply.started":"2024-11-12T06:58:25.637016Z","shell.execute_reply":"2024-11-12T06:58:25.828142Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# torch.cuda.empty_cache()\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:58:37.386937Z","iopub.execute_input":"2024-11-12T06:58:37.387338Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save training metrics to a JSON file\nmetrics = train_output.metrics\nwith open(\"training_metrics.json\", \"w\") as f:\n    json.dump(metrics, f, indent=4)\n\n# Optionally, evaluate and save evaluation metrics\neval_metrics = trainer.evaluate()\nwith open(\"eval_metrics.json\", \"w\") as f:\n    json.dump(eval_metrics, f, indent=4)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"custom_input = \"जब मैंने उसे देखा तो वह मंदिर जा रहा था\"\ninput_dict = {'text': [custom_input]}\ninput_dict = {'input_ids': [tokenizer.encode(custom_input)]}\ninput_dict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:51:05.003720Z","iopub.execute_input":"2024-11-12T06:51:05.004923Z","iopub.status.idle":"2024-11-12T06:51:05.012024Z","shell.execute_reply.started":"2024-11-12T06:51:05.004855Z","shell.execute_reply":"2024-11-12T06:51:05.010969Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"custom_dataset = Dataset.from_dict(input_dict)\npredictions = trainer.predict(custom_dataset)\ngenerated_outputs = predictions.predictions  # This will be logits\noutput_ids = torch.argmax(torch.tensor(generated_outputs), dim=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:51:06.085938Z","iopub.execute_input":"2024-11-12T06:51:06.086379Z","iopub.status.idle":"2024-11-12T06:51:06.127093Z","shell.execute_reply.started":"2024-11-12T06:51:06.086327Z","shell.execute_reply":"2024-11-12T06:51:06.126083Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer.decode(output_ids[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:51:06.604981Z","iopub.execute_input":"2024-11-12T06:51:06.605379Z","iopub.status.idle":"2024-11-12T06:51:06.611880Z","shell.execute_reply.started":"2024-11-12T06:51:06.605344Z","shell.execute_reply":"2024-11-12T06:51:06.610972Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output_ids","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:49:55.187994Z","iopub.execute_input":"2024-11-12T06:49:55.188375Z","iopub.status.idle":"2024-11-12T06:49:55.199352Z","shell.execute_reply.started":"2024-11-12T06:49:55.188341Z","shell.execute_reply":"2024-11-12T06:49:55.198333Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import math\nmodel = AutoModelForCausalLM.from_pretrained('trained_model')\ndef calculate_perplexity(text):\n    inputs = tokenizer(text, return_tensors=\"pt\")\n    input_ids = inputs[\"input_ids\"]\n\n    with torch.no_grad():\n        outputs = model(input_ids, labels=input_ids)\n        loss = outputs.loss\n        perplexity = math.exp(loss.item())\n\n    return perplexity\n\ntext = \"जब मैंने उसे देखा तो वह मंदिर जा रहा था\"\nperplexity = calculate_perplexity(text)\nprint(f\"Perplexity: {perplexity}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:55:27.284911Z","iopub.execute_input":"2024-11-12T06:55:27.285311Z","iopub.status.idle":"2024-11-12T06:55:27.389745Z","shell.execute_reply.started":"2024-11-12T06:55:27.285271Z","shell.execute_reply":"2024-11-12T06:55:27.388741Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.save_model(\"trained_model\")\ntokenizer.save_pretrained(\"trained_model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:49:56.681197Z","iopub.execute_input":"2024-11-12T06:49:56.681924Z","iopub.status.idle":"2024-11-12T06:49:57.472390Z","shell.execute_reply.started":"2024-11-12T06:49:56.681867Z","shell.execute_reply":"2024-11-12T06:49:57.471416Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}